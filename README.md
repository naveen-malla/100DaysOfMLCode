
**DAY 1**: 
Today I've learned about Data Preprocessing:
* Importing the libraries
* Importing the dataset
* Taking care of missing data
* Encoding categorical data
* Splitting the dataset into the Training set and Test set
* Feature Scaling\
Source: [Machine Learning A-Z™: Hands-On Python & R In Data Science](https://www.udemy.com/course/machinelearning/)
[Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/DataPreprocessing/data_preprocessing_tools.ipynb)\
[LinkedIn Post](https://www.linkedin.com/posts/naveen-malla_100daysofmlcode-machinelearning-datascience-activity-6702256267097968641-rxEO)

**DAY 2**:
Today I've learned and implemented Simple Linear Regression.
[Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Regression/simple_linear_regression.ipynb)\
[LindedIn Post](https://www.linkedin.com/posts/naveen-malla_google-colaboratory-activity-6702620874555633664-Vy72)

**DAY 3**:
Started reading a book called "Naked Statistics: Stripping the Dread from the Data" by Charles Wheelan.\
Today I've learned about 
* Multiple Linear Regression. [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Regression/multiple_linear_regression.ipynb)
* Backward Elimination
* Forward Selection
* Bidirectional Elimination\
[LinkedIn Post](https://www.linkedin.com/posts/naveen-malla_100daysofmlcode-machinelearning-datascience-activity-6702964440360480768-iKxO)

**DAY 4**:
Today I've learned and implemented Polynomial Regression.
[Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Regression/polynomial_regression.ipynb)\
[LinkedIn Post](https://www.linkedin.com/posts/naveen-malla_google-colaboratory-activity-6703330580492382208-0bAF)

**DAY 5**:
Today I've learned and implemented SVR model. 
[Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Regression/support_vector_regression.ipynb)\
[LinkedIn Post](https://www.linkedin.com/posts/naveen-malla_google-colaboratory-activity-6703672520643624960-OCH5)


**DAY 6**:
Today I've learned and implemented:
* Decision Tree Regression. [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Regression/decision_tree_regression.ipynb)
* Random Forest Regression. [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Regression/random_forest_regression.ipynb)
* R-Squared and Adjusted R-Squared

**DAY 7**:
Today I've learned and implemented Logistic Regression. [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Classification/logistic_regression.ipynb)

**DAY 8**:
Today I've learned and implemented:
* K-Nearest Neighbors(K-NN) [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Classification/k_nearest_neighbors.ipynb)
* Support Vector Machine(SVM) [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Classification/support_vector_machine.ipynb)
* Kernel SVM [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Classification/kernel_svm.ipynb)

**DAY 9**:
Today I've learned and implemented:
* Naive Bayes Classification [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Classification/naive_bayes.ipynb)
* Decision Tree Classification [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Classification/decision_tree_classification.ipynb)
* Random Forest Classification [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Classification/random_forest_classification.ipynb)

**DAY 10**:
Today I've learned about False Positives & False Negatives, Confusion Matrix, Accuracy Paradox, CAP Curve.

**DAY 11**:
Today I've learned and implemented K-Means Clustering. [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Clustering/k_means_clustering.ipynb)

**DAY 12**:
Today I've learned and implemented Hierarchical Clustering. [Code](https://github.com/naveenmalla046/100DaysOfMLCode/blob/master/Clustering/hierarchical_clustering.ipynb)

**DAY 13-20**:
I've completed the [Machine Learning A-Z](https://www.udemy.com/course/machinelearning/) course on Udemy. I've also completed reading the book "Naked Statistics" by Charles Wheelan.\
[LinkedIn Post](https://www.linkedin.com/posts/naveen-malla_100daysofmlcode-machinelearning-datascience-activity-6709860943465205760-dFZ6)

**DAY 21-25**:
I’ve learned and practiced Numpy, Pandas, and Tensorflow. I’ve also done some basic ML projects like text classification (Fashion MNIST) and text classification (IMDB reviews) based on some youtube tutorials.

**DAY 26**:
Resuming after a break. Revised ML course by Andrew NG on coursera. Completed two weeks' content and assignments. Working on optional assignments. [Course Link](https://www.coursera.org/learn/machine-learning)

**DAY 27, 28**:
Completed the optional assignments on Multivariate Cost function, Gradient Descent and Normal equation. Learned and implemented vectorization of cost function and gradient descent for easy coding in octave.

**DAY 29**:
Revised concepts of Deep learning. Understood the concept with an example of Demand Prediction of a product.

**DAY 30**:
Reviced concepts of Gradient Descent and Back Propagation.

**DAY 30**:
Learned how to implement forward propagation in neural networks using numpy.

**DAY 31**:
Implemented forward propagation using tensorflow and numpy

**DAY 32**:
Introduction to Multi class regression and softmax function.

**DAY 33**:
Got a better and deeper understanding of how Back Propagation works and why it's very important in neural networks.

**DAY 34**:
Started with GenAI with LLMs course on Coursera. Revised the working of transformer.

**DAY 35**:
Learned about bias and variance in ML models.

**DAY 36**:
Revised concept of text generation with transformers.

**DAY 37**:
Revised concept of prompt engineering.

**DAY 38**:
Intro to decison trees.

**DAY 39**:
Intro to clustering. 

**DAY 40**:
Learned about K-means clustering. 

**DAY 41**:
Learned about optimising K-means algorithm.

**DAY 42**:
Experimented with prompt engineering.

**DAY 43**:
Introduction to anamoly detection.

**DAY 44**:
Revised concept of Normal distribution.

**DAY 45**:
Learned to build Anamoly detection algorithm. 

**DAY 46**:
Learned the difference between Anamoly detection vs supervised learning and choosing features.

**DAY 47**:
Introduction to Recommender Systems.

**DAY 48**:
Learned about collaborative filterng and implementing Recommender systems using tensorflow. 

**DAY 49**:
Learned the differences between Collaborative filtering and Content baded filtering. 

**DAY 50**:
Learned implementation of Collaborative filtering using neural networks and with tensor flow. 

**DAY 51**:
Learned the concept and implementation of PCA. 

**DAY 52**:
Reviewed reinforcement learning and learned about state action value function with example of a rover landing on moon.

**DAY 53**:
Introduction to reinforcement learning with human feedback for LLMs.

**DAY 54**:
Learned about variational graph auto encoders. 

**DAY 55**:
Learned about VAEs vs VGAEs. 

**DAY 56**:
Learned about techniques used to get better accuracy on ML models. 

**DAY 57**:
Learned about data imputation techniques. 

**DAY 58**:
Explorer various feature engineering techniques. 

**DAY 59**:
Worked on Digit recognizer.  

**DAY 60**:
Learned about fine tuning LLMs.

**DAY 61**:
Learned about dealing with imbalanced datasets. 

**DAY 62**:
Introduction to AutoML. 

**DAY 63**:
Worked on digit recognition. 

**DAY 64**:
Revised multi head attention concept with calculation. 

**DAY 65**:
Learned about ways to enhance nueral network trainings with methods like Batch Normalization and so. 

**DAY 66**:
Revised some interesting pandas methods. 

**DAY 67**:
Learned about some interesting python libraries like pydantic, hypothesis, etc.

**DAY 68**:
Learned about time series forecasting and methods to implement it.

**DAY 69**:
Tips about reading research papers and learned to use Jupyter better with extensions

**DAY 70**:
Active Learning strategies 

**DAY 71**:
Explored the code for the project "Predicting Credit Card Approvals using Machine Learning"

**DAY 72**:
Explored ways to fill missing data with Python. 

**DAY 73**:
Explored the concept of uplift modelling.  

**DAY 74**:
Explored Visualizations in Multivariate cases. 

**DAY 75**:
Explored Neural Network embeddings and visualizations. 

**DAY 76**:
Explored the process of installing Hugging face transformers. 

**DAY 77**:
Read medium article on Churn Analysis. 

**DAY 78**:
Read medium article on analysing and calculating p-value. 

**DAY 79**:
Read medium article on NLP RELIC

**DAY 80**:
Read medium article about Plotly and using it for creating interactive visualizations. 

**DAY 81**:
Read medium article about scraping linkedin profiles and using Langchain. 

**DAY 82**:
Read medium article about EDA. 

**DAY 83**:
Read medium article about Grokking. 

**DAY 84**:
Read medium article about Data imputation. 

**DAY 85**:
Read Medium article about Decision tree classifier. 

**DAY 86**:
Read Medium article about Time series forecasting with Transformers. 

**DAY 87**:
Read Medium article about using Pyspark for data analysis. 

**DAY 88**:
Read Medium article about Time Series Forecasting with TimeMixer. 

**DAY 89**:
Read Medium article on Deploying Machine learning model. 

**DAY 90**:
Read Medium article on Scaling Numerical features. 

**DAY 91**:
Read Medium article on Sarcasm detection with NLP. 

**DAY 92**:
Followed turorial on trend detection on Kaggle. 

**DAY 93**:
Followed turorial on trend detection on Kaggle. 

**DAY 94**:
Followed turorial on trend detection on Kaggle. 

**DAY 95**:
Read Medium article on Cleaning the data for NLP tasks.

**DAY 96**:
Did Exercise on Time series forecasting on kaggle.

**DAY 97**:
Read Medium article on GPU requirements for LLMs. 

**DAY 98**:
Read Medium article on Hybrid Classifiers in Time Series.

**DAY 99**:
Read Medium article on Stacking with ensemble models. 

**DAY 100**:
Read Medium article on ensemble methods.

**DAY 101**:
Read Medium arricle on automated feature engineering with featuretools. 

**DAY 102**:
Read Medium article on stacking ml methods. 

**DAY 103**:
Read Medium article on implementing transformers with pytorch. 

**DAY 104**:
Read Medium article on K-L Divergence. 

**DAY 105**:
Read Medium article on feature engineering. 

**DAY 106**:
Did exercise on Time series forecasting on Kaggle. 

**DAY 107**:
Studied K fold and stratified validation. 

**DAY 108**:
Read Medium article on implementing PCA. 

**DAY 109**:
Read Medium article comparing Linear Regression, XG-Boost and Gaussian Preditions.

**DAY 110**:
Read Medium article about P values.

**DAY 111**:
Read Medium article about Classification project. 

**DAY 112**:
Read Medium article about Boltzmann Machines.

**DAY 113**:
Read Medium article on San fransisco crime classification EDA. 

**DAY 114**:
Read Medium article on dockerizing machine learning model. 

**DAY 115**:
Read Medium article on SQL functions for data analysis. 

**DAY 116**:
Read Medium article on running LLAMA on local machine. 

**DAY 117**:
Read Medium article on A/B testing in Data Science

**DAY 118**:
Worked on San Francisco crime dataset challenge on kaggle. 

**DAY 119**:
Read Medium article on deploying ML models with docker. 

**DAY 120**:
Read Medium article on SMOTE

**DAY 121**:
Read Medium article on Thompson Sampling and one arm bandit. 

**DAY 122**:
Read Medium article on Logistic Regression. 

**DAY 123**:
Read Medium article on Downloading amd transcribing Youtube Videos. 

**DAY 124**:
Read Medium article on Featuretools. 

**DAY 125**:
Read Medium article on ARIMA. 

**DAY 126**:
Read Medium article on using LLMs and Retrieval Augmented Classification for classification tasks. 

**DAY 127**:
Revised several data science concepts. 

**DAY 128**:
Revised different types of Classification algorithms. 

**DAY 129**:
Read Medium article on Latest research papers on Machine Learning. 

**DAY 130**:
Read Medium article about Movie reccomender system 

**DAY 131**:
Read Medium article about addressing missing data. 
